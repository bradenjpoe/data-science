{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECON 690 Python Project: Prediction Air BnB Prices in New York\n",
    "## Braden Poe and Kevin Van Lieshout\n",
    "\n",
    "### Outline Price Prediction:\n",
    "1. Import necesary packages for the project\n",
    "2. Download the data, analyze it, explain the variables, hot encode our categorical variables and do some feature selection based on high correlations\n",
    "3. Break our data into testing and training samples\n",
    "4. Run some normal ML models on the data to look at Root Mean Squared error evaluation\n",
    "    - Linear Regression\n",
    "    - Ridge Regression\n",
    "        - Do a small analysis for the best alpha learning rate based on RMSE\n",
    "    - Lasso Regression\n",
    "    - Decision Tree Regression\n",
    "    - Neural Net\n",
    "    - Random Forest Regression\n",
    "        - Run feature importance analysis for best explanation and re run the model with this new subset of data to see if it performs better\n",
    "5. Reset the data and run a model that needs standardized data. We standardize the data and then run:\n",
    "    - K Nearest Neighbors Regression\n",
    "6. Reset the data again and now lets examine some different kinds of Emsemble models for better predictions\n",
    "    - Voting Method using Lasso, Linear Regression and a Random Forest Regression\n",
    "    - A Bagging Regressor using a RF Regressor as it's baseline model\n",
    "    - An AdaBoost Regressor\n",
    "    - A Gradient Boosting Regressor\n",
    "    - A XG Boosting Regressor\n",
    "7. Greedy Algorithms\n",
    "    - Recursive Feature Elimination with\n",
    "        - Linear Regression \n",
    "        - Lasso Regression\n",
    "        - Random Forest Regressor\n",
    "7. Evaluate how our models performed and which one seems optimal \n",
    "\n",
    "### Outline Rental Probability Prediction:\n",
    "1. Clean up the data and grab the data needed for rental probaility \n",
    "2. Create dummies that are needed\n",
    "3. Run the logistic regression model \n",
    "    - Analyze the confusion matrix \n",
    "4. Analyze the ROC curve for True Positives and False Positives\n",
    "5. Fix the dataset to upload into a different heat map\n",
    "6. Run the heat map analysis \n",
    "7. Evaluate how the models performed "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**As a warning, some of these models are pretty indepth and may be computationally expensive in terms of time.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1). Import necesary packages for the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fiona\n",
      "  Using cached https://files.pythonhosted.org/packages/be/04/31d0a6f03943b1684f32c9b861be40c1fd282468fa6bd54ddf4a774e6b0f/Fiona-1.8.13.tar.gz\n",
      "    Complete output from command python setup.py egg_info:\n",
      "    A GDAL API version must be specified. Provide a path to gdal-config using a GDAL_CONFIG environment variable or use a GDAL_VERSION environment variable.\n",
      "    \n",
      "    ----------------------------------------\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Command \"python setup.py egg_info\" failed with error code 1 in C:\\Users\\KVANLI~1\\AppData\\Local\\Temp\\pip-install-r6j3ikg2\\fiona\\\n"
     ]
    }
   ],
   "source": [
    "pip install fiona\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'geopandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-ab122a0f7ef7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'matplotlib'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'inline'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mgeopandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mgpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfiona\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'geopandas'"
     ]
    }
   ],
   "source": [
    "##Import anything we could possibly need\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "from sklearn import metrics\n",
    "%matplotlib inline\n",
    "import geopandas as gpd\n",
    "from matplotlib import cm\n",
    "import fiona\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import timeit\n",
    "from sklearn.model_selection import train_test_split \n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.ensemble.forest import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import Ridge\n",
    "import preprocessing \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import mglearn\n",
    "from sklearn.linear_model import Lasso\n",
    "import xgboost as xg\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sklearn.preprocessing\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression, LassoCV, RidgeCV\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import math\n",
    "import xgboost as xgb\n",
    "import geopandas as gpd\n",
    "from matplotlib import cm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Download the data, analyze it, explain the variables, hot encode our categorical variables and do some feature selection based on high correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in the data and drop columns that don't help us. And subset the data based on counts of air bnbs by neighborhood\n",
    "df=pd.read_csv('~/Downloads/final.csv')\n",
    "\n",
    "nbcounts=df.groupby([ \"BOROUGH\",'neighbourhood'])['price'].count()\n",
    "df.drop(columns=['last_review','BOROUGH','Unnamed: 0','Unnamed: 0.1','id','name','host_name','host_id','latitude','longitude'],inplace=True)\n",
    "nbcounts=pd.DataFrame(nbcounts)\n",
    "nbcounts.rename(columns={'price':'counts'},inplace=True)\n",
    "\n",
    "nbcounts.reset_index('neighbourhood',inplace=True)\n",
    "df=pd.merge(df,nbcounts,how='left',on=['neighbourhood'])\n",
    "med=df['price'].median()\n",
    "std=df['price'].std()\n",
    "\n",
    "df = df[df['counts']>= 100] \n",
    "df = df[(df['price']< med+2.56*std)&(df['price']> med-2.56*std)] \n",
    "\n",
    "df.drop(columns=['neighbourhood'],inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze some heat maps of room and home prices in NYC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "room = pd.read_csv('bnbroom.csv',na_values=\"\")\n",
    "home = pd.read_csv('bnbhome.csv',na_values=\"\")\n",
    "fp = \"nynta_19c/nynta.shp\"\n",
    "map_df = gpd.read_file(fp)\n",
    "map_df.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergedroom = map_df.set_index('NTAName').join(room.set_index('NTAName'))\n",
    "mergedroom['roomprice'] = mergedroom['roomprice'].round(2)\n",
    "mergedroom  = mergedroom.fillna(np.nan)\n",
    "mergedhome = map_df.set_index('NTAName').join(home.set_index('NTAName'))\n",
    "mergedhome['homeprice'] = mergedhome['homeprice'].round(2)\n",
    "mergedhome = mergedhome.fillna(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the range for the choropleth\n",
    "vmin, vmax = 0, 800.00\n",
    "# create figure and axes for Matplotlib\n",
    "fig, ax = plt.subplots(1, figsize=(10, 10))\n",
    "mergedhome.plot(column='homeprice', cmap='Blues', linewidth=0.8, ax=ax, edgecolor='0.8')\n",
    "ax.axis('off')\n",
    "\n",
    "ax.set_title('Airbnb Entire Home/Apt Prices in New York City', fontdict={'fontsize': '25', 'fontweight' : '3'})\n",
    "\n",
    "ax.annotate('Source: Kaggle NYC Open Data, 2019',xy=(0.1, .08),\n",
    "            xycoords='figure fraction', horizontalalignment='left',\n",
    "            verticalalignment='top', fontsize=12, color='#555555')\n",
    "sm = plt.cm.ScalarMappable(cmap='Blues', norm=plt.Normalize(vmin=vmin, vmax=vmax))\n",
    "sm._A = []\n",
    "cbar = fig.colorbar(sm,shrink = .65)\n",
    "\n",
    "fig.savefig('homeheatmap.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the range for the choropleth\n",
    "vmin, vmax = 0, 800.00\n",
    "# create figure and axes for Matplotlib\n",
    "fig, ax = plt.subplots(1, figsize=(10, 10))\n",
    "mergedroom.plot(column='roomprice', cmap='Reds', linewidth=0.8, ax=ax, edgecolor='0.8')\n",
    "ax.axis('off')\n",
    "\n",
    "ax.set_title('Airbnb Room Prices in New York City', fontdict={'fontsize': '25', 'fontweight' : '3'})\n",
    "\n",
    "ax.annotate('Source: Kaggle NYC Open Data, 2019',xy=(0.1, .08),\n",
    "            xycoords='figure fraction', horizontalalignment='left',\n",
    "            verticalalignment='top', fontsize=12, color='#555555')\n",
    "sm = plt.cm.ScalarMappable(cmap='Reds', norm=plt.Normalize(vmin=vmin, vmax=vmax))\n",
    "sm._A = []\n",
    "cbar = fig.colorbar(sm,shrink = .65)\n",
    "\n",
    "fig.savefig('roomheatmap.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove high correlated variables that won't help us\n",
    "threshold = 0.95\n",
    "\n",
    "# Calculate correlations\n",
    "corr_matrix = df.corr().abs()\n",
    "\n",
    "# Subset to the upper triangle of correlation matrix\n",
    "upper = corr_matrix.where(\n",
    "    np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "\n",
    "# Identify names of columns with correlation above threshold\n",
    "to_drop = [column for column in upper.columns if any(\n",
    "    upper[column] >= threshold)]\n",
    "print(\n",
    "    f'There are {len(to_drop)} columns to drop with correlation > {threshold}')\n",
    "print(\"These variables are:\",to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop these variables due to their correlations being incredibly high and they probably don't help our model\n",
    "df.drop(columns=to_drop,inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Figure out which columns are numerical and which are not\n",
    "\n",
    "def get_cols_with_no_nans(df,col_type):\n",
    "    '''\n",
    "    Arguments :\n",
    "    df : The dataframe to process\n",
    "    col_type : \n",
    "          num : to only get numerical columns with no nans\n",
    "          no_num : to only get nun-numerical columns with no nans\n",
    "          all : to get any columns with no nans    \n",
    "    '''\n",
    "    if (col_type == 'num'):\n",
    "        predictors = df.select_dtypes(exclude=['object'])\n",
    "    elif (col_type == 'no_num'):\n",
    "        predictors = df.select_dtypes(include=['object'])\n",
    "    elif (col_type == 'all'):\n",
    "        predictors = df\n",
    "    else :\n",
    "        print('Error : choose a type (num, no_num, all)')\n",
    "        return 0\n",
    "    cols_with_no_nans = []\n",
    "    for col in predictors.columns:\n",
    "        \n",
    "        cols_with_no_nans.append(col)\n",
    "    return cols_with_no_nans\n",
    "num_cols = get_cols_with_no_nans(df , 'num')\n",
    "cat_cols = get_cols_with_no_nans(df , 'no_num')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do a little correlation analysis on the variables\n",
    "corr = df.corr()\n",
    "fig = plt.figure(figsize = (14,10))\n",
    "sns.heatmap(corr,annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hot encode the categorical variable room type\n",
    "def oneHotEncode(df,colNames):\n",
    "    for col in colNames:\n",
    "        if( df[col].dtype == np.dtype('object')):\n",
    "            dummies = pd.get_dummies(df[col],prefix=col)\n",
    "            df = pd.concat([df,dummies],axis=1)\n",
    "\n",
    "            #drop the encoded column\n",
    "            df.drop([col],axis = 1 , inplace=True)\n",
    "    return df\n",
    "    \n",
    "\n",
    "print('There were {} columns before encoding categorical features'.format(df.shape[1]))\n",
    "df = oneHotEncode(df, cat_cols)\n",
    "\n",
    "\n",
    "print('There are {} columns after encoding categorical features'.format(df.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.set(color_codes=True)\n",
    "ax=sns.distplot(df.price)\n",
    "ax.set_title(\"Price Histogram\")\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Break our data into testing and training samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the lists of numerical variables and prediction variables so you can subset X and Y for train/test\n",
    "h=df.columns.tolist()\n",
    "g=['price']\n",
    "A=['price','BOROUGH','room_type_Shared room','room_type_Private room','room_type_Entire home/apt']\n",
    "\n",
    "\n",
    "num_cols=list(set(num_cols)-set(A))\n",
    "z=list(set(h)-set(g))\n",
    "X = df[z]\n",
    "y = df.price\n",
    "X.fillna(0, inplace=True)\n",
    "y.fillna(0, inplace=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, \n",
    "                                                    random_state=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run some normal ML models on the data to look at Root Mean Squared error evaluation\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create linear regression object \n",
    "import math\n",
    "\n",
    "t0 = timeit.default_timer()\n",
    "reg = linear_model.LinearRegression()\n",
    "  \n",
    "# train the model using the training sets \n",
    "reg.fit(X_train, y_train) \n",
    "  \n",
    "\n",
    "y_pred=reg.predict(X_test)\n",
    "print(\"The RMSE was:\",math.sqrt(metrics.mean_squared_error(y_test,y_pred)))\n",
    "# variance score: 1 means perfect prediction \n",
    "print('Variance score: {}'.format(reg.score(X_test, y_test)))\n",
    "\n",
    "t1 = timeit.default_timer()\n",
    "total_time = t1 - t0\n",
    "print ('This code took', total_time, 'seconds')  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ridge Regression with best alpha selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "t0 = timeit.default_timer()#Search for best alphas in the ridge model\n",
    "ridge = linear_model.RidgeCV(alphas = [ 0.1, 10, 20, 30])\n",
    "ridge.fit(X_train, y_train)\n",
    "alpha = ridge.alpha_\n",
    "print(\"Best alpha :\", alpha)\n",
    "\n",
    "print(\"Try again for more precision with alphas centered around \" + str(alpha))\n",
    "ridge = linear_model.RidgeCV(alphas = [alpha * .6, alpha * .65, alpha * .7, alpha * .75, alpha * .8, alpha * .85, \n",
    "                          alpha * .9, alpha * .95, alpha, alpha * 1.05, alpha * 1.1, alpha * 1.15,\n",
    "                          alpha * 1.25, alpha * 1.3, alpha * 1.35, alpha * 1.4], cv = 10)\n",
    "\n",
    "ridge.fit(X_train, y_train)\n",
    "alpha = ridge.alpha_\n",
    "print(\"Best alpha :\", alpha)\n",
    "y_pred = ridge.predict(X_test)\n",
    "print(\"The RMSE is: %.5f\" % math.sqrt(metrics.mean_squared_error(y_test,y_pred)))\n",
    "print(ridge.score(X_test, y_test))\n",
    "t1 = timeit.default_timer()\n",
    "total_time = t1 - t0\n",
    "print ('This code took', total_time, 'seconds') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = timeit.default_timer()\n",
    "#run lasso model with .01 learning rate\n",
    "lasso1 = Lasso(alpha=.01,max_iter=100000).fit(X_train, y_train)\n",
    "print(\"Training Lasso score is : {:.2f}\".format(lasso1.score(X_train,y_train)))\n",
    "print(\"Test Lasso score is : {:.2f}\".format(lasso1.score(X_test,y_test)))\n",
    "print(\"Number of features used: {}\".format(np.sum(lasso1.coef_ !=0)))\n",
    "y_pred=lasso1.predict(X_test)\n",
    "print(\"The RMSE was:\",math.sqrt(metrics.mean_squared_error(y_test,y_pred)))\n",
    "t1 = timeit.default_timer()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lasso searching with cross validation and finding the best alpha to use "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "t0 = timeit.default_timer()\n",
    "lasso=Lasso()\n",
    "parameters={'alpha':[1e-18,1e-16,1e-15,1e-10,1e-8,1e-4,1e-3,1e-2,1,5,10,20]}\n",
    "lasso_reg=GridSearchCV(lasso,parameters,scoring='neg_mean_squared_error',cv=5)\n",
    "lasso_reg.fit(X_train,y_train)\n",
    "alpha=lasso_reg.best_params_\n",
    "alpha=alpha['alpha']\n",
    "best=lasso_reg.best_score_\n",
    "lasso = Lasso(alpha=alpha,max_iter=100000).fit(X_train, y_train)\n",
    "print(\"Training Lasso score is : {:.2f}\".format(lasso.score(X_train,y_train)))\n",
    "print(\"Test Lasso score is : {:.2f}\".format(lasso.score(X_test,y_test)))\n",
    "print(\"Number of features used: {}\".format(np.sum(lasso.coef_ !=0)))\n",
    "y_pred=lasso.predict(X_test)\n",
    "print(\"The RMSE was:\",math.sqrt(metrics.mean_squared_error(y_test,y_pred)))\n",
    "t1 = timeit.default_timer()\n",
    "total_time = t1 - t0\n",
    "print ('This code took', total_time, 'seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Decision Tree Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = timeit.default_timer()\n",
    "#Run decision tree with max of 4 levels\n",
    "tree1=DecisionTreeRegressor(max_depth=4,random_state=0).fit(X_train,y_train)\n",
    "print(\"Train:\", tree1.score(X_train,y_train))\n",
    "print(\"Test:\", tree1.score(X_test,y_test))\n",
    "y_pred=tree1.predict(X_test)\n",
    "print(\"The RMSE was:\",math.sqrt(metrics.mean_squared_error(y_test,y_pred)))\n",
    "t1 = timeit.default_timer()\n",
    "total_time = t1 - t0\n",
    "print ('This code took', total_time, 'seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Neural Net Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.data import Dataset\n",
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "from keras import models\n",
    "from keras import layers\n",
    "model = keras.Sequential([\n",
    " keras.layers.Dense(64, activation=tf.nn.relu,                  \n",
    " input_shape=(X_train.shape[1],)),\n",
    " keras.layers.Dense(64, activation=tf.nn.relu),\n",
    " keras.layers.Dense(12000, activation=  'softmax')\n",
    " ])\n",
    "\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "history2 = model.fit(\n",
    " X_train, y_train,\n",
    " epochs= 26, batch_size = 60,\n",
    " validation_data = (X_test, y_test))\n",
    "y_pred=model.predict(X_test)\n",
    "print(\"The RMSE was:\",math.sqrt(math.sqrt(metrics.mean_squared_error(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = timeit.default_timer()\n",
    "#Run Random Forest Regressor\n",
    "forest=RandomForestRegressor(random_state=1)\n",
    "forest.fit(X_train,y_train)\n",
    "print(\"Training score accuracy is : {:.2f}\".format(forest.score(X_train,y_train)))\n",
    "print(\"Test score accuracy is : {:.2f}\".format(forest.score(X_test,y_test)))\n",
    "y_pred=forest.predict(X_test)\n",
    "print(\"The RMSE was:\",math.sqrt(metrics.mean_squared_error(y_test,y_pred)))\n",
    "t1 = timeit.default_timer()\n",
    "total_time = t1 - t0\n",
    "print ('This code took', total_time, 'seconds')\n",
    "#Plot the feature importance from the forest model since it will help us. \n",
    "def plot_feature_importances_cancer(model):\n",
    "    n_features = X.shape[1]\n",
    "    plt.barh(range(n_features),model.feature_importances_,align='center')\n",
    "    plt.yticks(np.arange(n_features),X.columns)\n",
    "    plt.xlabel(\"Feature Importance\")\n",
    "    plt.ylabel(\"Feature\")\n",
    "    plt.ylim(-1,n_features)\n",
    "\n",
    "plot_feature_importances_cancer(forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Find the most import features based on criteria above and in the selection model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reset the data to the what the importance feature exercise showed us\n",
    "t0 = timeit.default_timer()\n",
    "sel = SelectFromModel(RandomForestRegressor())\n",
    "sel.fit(X_train, y_train)\n",
    "selected_feat= X_train.columns[(sel.get_support())]\n",
    "print(\"There are\",len(selected_feat),\"important features.\")\n",
    "print(selected_feat)\n",
    "pd.Series(sel.estimator_.feature_importances_.ravel()).hist()\n",
    "X_train=X_train.filter(items=selected_feat)\n",
    "X_test=X_test.filter(items=selected_feat)\n",
    "t1 = timeit.default_timer()\n",
    "forest=RandomForestRegressor(random_state=1)\n",
    "forest.fit(X_train,y_train)\n",
    "print(\"Training score accuracy is : {:.2f}\".format(forest.score(X_train,y_train)))\n",
    "print(\"Test score accuracy is : {:.2f}\".format(forest.score(X_test,y_test)))\n",
    "y_pred=forest.predict(X_test)\n",
    "print(\"The new RMSE was:\",math.sqrt(metrics.mean_squared_error(y_test,y_pred)))\n",
    "total_time = t1 - t0\n",
    "print ('This code took', total_time, 'seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Reset the data and run a model that needs standardized data. We standardize the data and then run:\n",
    "    - K Nearest Neighbors Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reset the data\n",
    "h=df.columns.tolist()\n",
    "g=['price']\n",
    "A=['price','BOROUGH','room_type_Shared room','room_type_Private room','room_type_Entire home/apt']\n",
    "\n",
    "\n",
    "num_cols=list(set(num_cols)-set(A))\n",
    "z=list(set(h)-set(g))\n",
    "X = df[z]\n",
    "y = df.price\n",
    "X.fillna(0, inplace=True)\n",
    "y.fillna(0, inplace=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, \n",
    "                                                    random_state=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize the X for KNN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "# Fit on training set only.\n",
    "\n",
    "scaler.fit(X_train)\n",
    "# Apply transform to both the training set and the test set.\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test_norm = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Run a nearest neighbors function \n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "knn = KNeighborsRegressor(n_neighbors=12)\n",
    "\n",
    "knn.fit(X_train, y_train)\n",
    "predictions = knn.predict(X_test)\n",
    "print(\"Training score accuracy is : {:.2f}\".format(knn.score(X_train,y_train)))\n",
    "print(\"Test score accuracy is : {:.2f}\".format(knn.score(X_test,y_test)))\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "rmse = two_features_mse ** (1/2)\n",
    "print(\"The RMSE was:\"rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Reset the data again and now lets examine some different kinds of Emsemble models for better predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reset the data from being standardized with the same random_state\n",
    "h=df.columns.tolist()\n",
    "g=['price']\n",
    "A=['price','BOROUGH','room_type_Shared room','room_type_Private room','room_type_Entire home/apt']\n",
    "\n",
    "\n",
    "num_cols=list(set(num_cols)-set(A))\n",
    "z=list(set(h)-set(g))\n",
    "X = df[z]\n",
    "y = df.price\n",
    "X.fillna(0, inplace=True)\n",
    "y.fillna(0, inplace=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, \n",
    "                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Voting Method using Lasso, Linear Regression and a Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = RandomForestRegressor()\n",
    "model2 = Lasso()\n",
    "model3= LinearRegression()\n",
    "\n",
    "model1.fit(X_train,y_train)\n",
    "model2.fit(X_train,y_train)\n",
    "model3.fit(X_train,y_train)\n",
    "\n",
    "pred1=model1.predict(X_test)\n",
    "pred2=model2.predict(X_test)\n",
    "pred3=model3.predict(X_test)\n",
    "\n",
    "final_pred = np.array([])\n",
    "for i in range(0,len(X_test)):\n",
    "    final_pred = np.append(final_pred, np.mean([pred1[i], pred2[i], pred3[i]]))\n",
    "rmse=math.sqrt(metrics.mean_squared_error(y_test,final_pred))\n",
    "print(\"The RMSE was:\",rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Bagging regressor with a random forest regressor as its baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn import tree\n",
    "model = BaggingRegressor(RandomForestRegressor())\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Training score accuracy is : {:.2f}\".format(model.score(X_train,y_train)))\n",
    "print(\"Test score accuracy is : {:.2f}\".format(model.score(X_test,y_test)))\n",
    "final_pred=model.predict(X_test)\n",
    "rmse=math.sqrt(metrics.mean_squared_error(y_test,final_pred))\n",
    "print(\"The RMSE was:\",rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ada Boosting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "model = AdaBoostRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test,y_test)\n",
    "print(\"Training score accuracy is : {:.2f}\".format(model.score(X_train,y_train)))\n",
    "print(\"Test score accuracy is : {:.2f}\".format(model.score(X_test,y_test)))\n",
    "final_pred=model.predict(X_test)\n",
    "rmse=math.sqrt(metrics.mean_squared_error(y_test,final_pred))\n",
    "print(\"The RMSE was:\",rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "model= GradientBoostingRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test,y_test)\n",
    "print(\"Training score accuracy is : {:.2f}\".format(model.score(X_train,y_train)))\n",
    "print(\"Test score accuracy is : {:.2f}\".format(model.score(X_test,y_test)))\n",
    "final_pred=model.predict(X_test)\n",
    "rmse=math.sqrt(metrics.mean_squared_error(y_test,final_pred))\n",
    "print(\"The RMSE was:\",rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- XGBoost Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "model=xgb.XGBRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test,y_test)\n",
    "print(\"Training score accuracy is : {:.2f}\".format(model.score(X_train,y_train)))\n",
    "print(\"Test score accuracy is : {:.2f}\".format(model.score(X_test,y_test)))\n",
    "final_pred=model.predict(X_test)\n",
    "rmse=math.sqrt(metrics.mean_squared_error(y_test,final_pred))\n",
    "print(\"The RMSE was:\",rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Greedy Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- RFE feature selection with Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "t0 = timeit.default_timer()\n",
    "from sklearn.feature_selection import RFE\n",
    "nof_list = np.arange(1,20)\n",
    "best_score=120\n",
    "#Variable to store in the optimum features\n",
    "nof=0\n",
    "score_list=[]\n",
    "for n in range(len(nof_list)):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "    model=LinearRegression()\n",
    "    rfe=RFE(model,nof_list[n])\n",
    "    X_train_rfe=rfe.fit_transform(X_train,y_train)\n",
    "    X_test_rfe=rfe.transform(X_test)\n",
    "    model.fit(X_train_rfe,y_train)\n",
    "    y_pred=model.predict(X_test_rfe)\n",
    "    score= math.sqrt(metrics.mean_squared_error(y_pred,y_test))\n",
    "    score_list.append(score)\n",
    "    print(score)\n",
    "    if(score<best_score):\n",
    "        best_score=score\n",
    "\n",
    "        nof=nof_list[n]  \n",
    "\n",
    "print(\"Optimum number of features for the Linear Reg was: %d\" %nof)\n",
    "print(\"Score with %d features: %f\" % (nof, best_score))\n",
    "\n",
    "t1 = timeit.default_timer()\n",
    "total_time = t1 - t0\n",
    "print ('This code took', total_time, 'seconds') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- RFE feature selection with Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "t0 = timeit.default_timer()\n",
    "from sklearn.feature_selection import RFE\n",
    "nof_list = np.arange(1,20)\n",
    "best_score=120\n",
    "#Variable to store in the optimum features\n",
    "nof=0\n",
    "score_list=[]\n",
    "for n in range(len(nof_list)):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "    model=Lasso()\n",
    "    rfe=RFE(model,nof_list[n])\n",
    "    X_train_rfe=rfe.fit_transform(X_train,y_train)\n",
    "    X_test_rfe=rfe.transform(X_test)\n",
    "    model.fit(X_train_rfe,y_train)\n",
    "    y_pred=model.predict(X_test_rfe)\n",
    "    score= math.sqrt(metrics.mean_squared_error(y_pred,y_test))\n",
    "    score_list.append(score)\n",
    "    print(score)\n",
    "    if(score<best_score):\n",
    "        best_score=score\n",
    "\n",
    "        nof=nof_list[n]  \n",
    "\n",
    "print(\"Optimum number of features for the Lasso regression was: %d\" %nof)\n",
    "print(\"Score with %d features: %f\" % (nof, best_score))\n",
    "\n",
    "t1 = timeit.default_timer()\n",
    "total_time = t1 - t0\n",
    "print ('This code took', total_time, 'seconds') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- RFE feature selection with Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "t0 = timeit.default_timer()\n",
    "from sklearn.feature_selection import RFE\n",
    "nof_list = np.arange(1,20)\n",
    "best_score=120\n",
    "#Variable to store in the optimum features\n",
    "nof=0\n",
    "score_list=[]\n",
    "for n in range(len(nof_list)):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "    model=RandomForestRegressor()\n",
    "    rfe=RFE(model,nof_list[n])\n",
    "    X_train_rfe=rfe.fit_transform(X_train,y_train)\n",
    "    X_test_rfe=rfe.transform(X_test)\n",
    "    model.fit(X_train_rfe,y_train)\n",
    "    y_pred=model.predict(X_test_rfe)\n",
    "    score= math.sqrt(metrics.mean_squared_error(y_pred,y_test))\n",
    "    score_list.append(score)\n",
    "    print(score)\n",
    "    if(score<best_score):\n",
    "        best_score=score\n",
    "\n",
    "        nof=nof_list[n]  \n",
    "\n",
    "print(\"Optimum number of features for the random forest regression was: %d\" %nof)\n",
    "print(\"Score with %d features: %f\" % (nof, best_score))\n",
    "\n",
    "t1 = timeit.default_timer()\n",
    "total_time = t1 - t0\n",
    "print ('This code took', total_time, 'seconds') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Evaluate how our models performed and which one seems optimal "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After investigation, there were models that performed pretty well, but it turns out that the use of ensemble methods in bagging helps our model perform the best. The Bagging ensemble method mixed with the use of a random forest had the best test root mean squared error of all of the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RENTAL PROBABILITY PREDICTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Clean up the data and grab the data needed for rental probaility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('updated.csv',na_values=\"\")\n",
    "data = data.dropna()\n",
    "data.drop(columns=['Unnamed: 0', 'Unnamed: 0.1'],inplace=True)\n",
    "data = data.loc[data['minimum_nights']<=3] #  Drop minimum nights that are greater than 1/2 a week \n",
    "\n",
    "cols = ['price','minimum_nights','number_of_reviews','availability_365','walk_score','transit_score','bike_score','BOROUGH','SALE PRICE','crimes','gdp_cap','rest','pop_dens','r_censor','room']\n",
    "y = data['r_censor']\n",
    "X = data[cols]\n",
    "X.to_csv('trimmed.csv')\n",
    "X = X.drop('r_censor',axis=1)\n",
    "X['room'] = X['room'].astype(int)\n",
    "X['minimum_nights'] = X['minimum_nights'].astype(int)\n",
    "X['BOROUGH'] = X['BOROUGH'].astype(int)\n",
    "X = X.rename(columns={'SALE PRICE': 'sale_price'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create dummies that are needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummies\n",
    "## At this point, the manipulation of our main datasets is complete.\n",
    "X['min_night1'] = 0\n",
    "X['min_night1'].loc[X['minimum_nights']==1] = 1\n",
    "X['min_night2'] = 0\n",
    "X['min_night2'].loc[X['minimum_nights']==2] = 2\n",
    "X['min_night3'] = 0\n",
    "X['min_night3'].loc[X['minimum_nights']==3] = 3\n",
    "X['boro1'] = 0\n",
    "X['boro1'].loc[X['BOROUGH']==1] = 1\n",
    "X['boro2'] = 0\n",
    "X['boro2'].loc[X['BOROUGH']==2] = 2\n",
    "X['boro3'] = 0\n",
    "X['boro3'].loc[X['BOROUGH']==3] = 3\n",
    "X['boro4'] = 0\n",
    "X['boro4'].loc[X['BOROUGH']==4] = 4\n",
    "X['boro5'] = 0\n",
    "X['boro5'].loc[X['BOROUGH']==5] = 5\n",
    "X['room0'] = 0\n",
    "X['room0'].loc[X['room']==0] = 0\n",
    "X['room1'] = 0\n",
    "X['room1'].loc[X['room']==1] = 1\n",
    "X['room2'] = 0\n",
    "X['room2'].loc[X['room']==2] = 2\n",
    "X = X.drop(['BOROUGH','minimum_nights','room'],axis=1)\n",
    "# Standardize certain columns \n",
    "cols_to_stan = ['price','number_of_reviews','availability_365','walk_score','transit_score','bike_score','sale_price','crimes','gdp_cap','rest','pop_dens']\n",
    "\n",
    "for i in cols_to_stan:\n",
    "    X[i] = (X[i] - X[i].mean())/X[i].std()\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "print(len(X_train))\n",
    "print(len(X_test))\n",
    "print(len(y_train))\n",
    "print(len(y_test))\n",
    "y_train = pd.DataFrame(y_train)\n",
    "y_train['r_censor'] = y_train['r_censor'].astype(int)\n",
    "y_test = pd.DataFrame(y_test)\n",
    "y_test['r_censor'] = y_test['r_censor'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run the logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "print('The MSE on the test sample is: {0}.'.format(round(mean_squared_error(y_test,y_pred),4)))\n",
    "score = logreg.score(X_test,y_test)\n",
    "print('The score of the model is: {0}.'.format(round(score,4)))\n",
    "y_pred = pd.DataFrame(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Look at the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Confusion Matrix \n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Analyze the ROC curve for True Positives and False Positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##ROC Curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "logit_roc_auc = roc_auc_score(y_test, logreg.predict(X_test))\n",
    "fpr, tpr, thresholds = roc_curve(y_test, logreg.predict_proba(X_test)[:,1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('Log_ROC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['pred'] = logreg.predict(X)\n",
    "X.head()\n",
    "X.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Fix the data up for heat map analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load original bnb data set \n",
    "bnb = pd.read_csv('final.csv')\n",
    "\n",
    "## Make equivalent modifications\n",
    "bnb = bnb.loc[bnb['minimum_nights']<=3]\n",
    "bnb = bnb.dropna()\n",
    "bnb.head()\n",
    "## Merge datasets in order to create heatmap\n",
    "merge = bnb.merge(X['pred'],left_index=True,right_index=True)\n",
    "merge.rename(columns={'neighbourhood':'NTAName'},inplace=True)\n",
    "merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load heatmap \n",
    "fp = \"nynta.shp\"\n",
    "map_df = gpd.read_file(fp)\n",
    "map_df.head()\n",
    "\n",
    "heatmap = pd.read_csv('heatmap.csv')\n",
    "# Merge \n",
    "heat = map_df.set_index('NTAName').join(heatmap.set_index('NTAName'))\n",
    "heat  = heat.fillna(0)\n",
    "heat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Heat map analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-eca3dbaefb8c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mvmin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvmax\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# create figure and axes for Matplotlib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mheat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'pred'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Greens'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlinewidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medgecolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'0.8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'off'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "## Rental heat maps\n",
    "# set the range for the choropleth\n",
    "vmin, vmax = 0, 1\n",
    "# create figure and axes for Matplotlib\n",
    "fig, ax = plt.subplots(1, figsize=(10, 10))\n",
    "heat.plot(column='pred', cmap='Greens', linewidth=0.8, ax=ax, edgecolor='0.8')\n",
    "ax.axis('off')\n",
    "\n",
    "ax.set_title('Airbnb Rental Probability\\nby Neighbourhood', fontdict={'fontsize': '25', 'fontweight' : '2'})\n",
    "\n",
    "ax.annotate('Source: Kaggle NYC Open Data, 2019',xy=(0.1, .08),\n",
    "            xycoords='figure fraction', horizontalalignment='left',\n",
    "            verticalalignment='top', fontsize=12, color='#555555')\n",
    "sm = plt.cm.ScalarMappable(cmap='Greens', norm=plt.Normalize(vmin=vmin, vmax=vmax))\n",
    "sm._A = []\n",
    "cbar = fig.colorbar(sm,shrink = .65)\n",
    "\n",
    "fig.savefig('rentalprobheat.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Evaluate how the model performed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model performed pretty well, the confusion matrix has more missed classifications than we would have liked, but the ROC curve looks okay and we showed good power in the logistic regression"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
